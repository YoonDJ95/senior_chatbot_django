import os
import pandas as pd
import numpy as np
import requests
from math import radians, sin, cos, sqrt, atan2
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv
import re
import json

# .env íŒŒì¼ì—ì„œ Kakao API í‚¤ ë¡œë“œ
load_dotenv()
kakao_api_key = os.getenv('KAKAO_API_KEY')

# í”¼ë“œë°± ê¸°ë¡ì„ ìœ„í•œ íŒŒì¼
feedback_file = "feedback.json"

# í”¼ë“œë°± ê¸°ë¡ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_feedback():
    if os.path.exists(feedback_file):
        with open(feedback_file, 'r') as file:
            return json.load(file)
    return {}

# í”¼ë“œë°± ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_feedback(feedback_data):
    with open(feedback_file, 'w') as file:
        json.dump(feedback_data, file)

# Kakao APIë¥¼ í†µí•´ ì…ë ¥ëœ ì£¼ì†Œë¥¼ êµ¬ì²´ì ì¸ ì£¼ì†Œë¡œ ë³€í™˜í•˜ê³ , ìœ„ë„, ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_lat_lon_from_address(address, api_key):
    headers = {"Authorization": f"KakaoAK {api_key}"}
    params = {"query": address}
    search_url = "https://dapi.kakao.com/v2/local/search/address.json"
    
    try:
        response = requests.get(search_url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        documents = response.json().get('documents', [])
        if documents:
            latitude = float(documents[0]['y'])
            longitude = float(documents[0]['x'])
            full_address = documents[0]['address_name']
            return full_address, latitude, longitude
        else:
            return None, None, None
    except requests.exceptions.RequestException as e:
        print(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None, None, None

# Haversine ê³µì‹ì„ ì‚¬ìš©í•´ ë‘ ì§€ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (km ë‹¨ìœ„)
def haversine(lat1, lon1, lat2, lon2):
    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:
        return None
    R = 6371.0  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    distance = R * c
    return distance

# ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì„ ì œê±°í•˜ê³  ì£¼ì†Œë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ìì—°ì–´ ì²˜ë¦¬ ì ìš©)
def extract_address(text):
    text = re.sub(r'ì— ìˆì–´|ì— ìœ„ì¹˜í•´|ì— ìˆìŠµë‹ˆë‹¤', '', text)
    return text.strip()

# í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ìœ„í•´ TF-IDF ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
def calculate_similarity(user_input, job_text):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([user_input, job_text])
    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
    return cosine_sim[0][0]

# ì…ë ¥ëœ ì§ˆë¬¸ì„ í‚¤ì›Œë“œë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ê°„ë‹¨í•œ ìì—°ì–´ ì²˜ë¦¬ ì ìš©)
def extract_keywords(text):
    # ì§ˆë¬¸ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
    text = text.lower().strip()
    keywords = re.findall(r'\b\w+\b', text)  # ë‹¨ì–´ë§Œ ì¶”ì¶œ
    return keywords

# í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìš°ì„ ìˆœìœ„ ì¡°ì • í•¨ìˆ˜
def adjust_priority_with_feedback(job, feedback_data):
    job_id = job['title']  # íƒ€ì´í‹€ì„ ê³ ìœ  IDë¡œ ì‚¬ìš© (í•„ìš”ì‹œ ê³ ìœ  IDë¥¼ ìƒì„±)
    feedback = feedback_data.get(job_id, None)
    
    if feedback == 'ë§ìŒ':  # ê³¼ê±° í”¼ë“œë°±ì—ì„œ ê¸ì •ì  ì‘ë‹µ
        job['priority_score'] -= 5  # ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¥¼ í¬ê²Œ ë‚®ì¶¤ (ì¦‰, ë” ìƒìœ„ì— í‘œì‹œë¨)
    elif feedback == 'í‹€ë¦¼':  # ë¶€ì •ì  ì‘ë‹µ
        job['priority_score'] += 5  # ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¥¼ ë†’ì„ (ì¦‰, í•˜ìœ„ë¡œ í‘œì‹œë¨)
    
    return job

# JobSearchChatbot í´ë˜ìŠ¤
class JobSearchChatbot:
    def __init__(self, job_data_file):
        self.df = pd.read_csv(job_data_file)
        self.feedback_data = load_feedback()  # í”¼ë“œë°± ë°ì´í„° ë¡œë“œ

    def find_jobs(self, user_input, user_lat, user_lon):
        keywords = extract_keywords(user_input)  # ì…ë ¥ëœ ì§ˆë¬¸ì„ í‚¤ì›Œë“œí™”
        
        matching_jobs = []

        # ê° ì¼ìë¦¬ì˜ ì„¤ëª…, í‚¤ì›Œë“œ, ì œëª©ê³¼ ì‚¬ìš©ì í‚¤ì›Œë“œ ë§¤ì¹­ (ì„¤ëª…, í‚¤ì›Œë“œ, ì œëª© ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì ìš©)
        for _, row in self.df.iterrows():
            description = str(row['description']).lower()
            keywords_field = str(row['keywords']).lower()
            title = str(row['title']).lower()

            # ê°ê°ì˜ í•„ë“œì™€ ë§¤ì¹­ë˜ëŠ” ì •ë„ë¥¼ í‰ê°€
            description_similarity = calculate_similarity(user_input, description)
            keywords_similarity = calculate_similarity(user_input, keywords_field)
            title_similarity = calculate_similarity(user_input, title)

            # ì´ ìœ ì‚¬ë„ ì ìˆ˜ (ì„¤ëª…ì— ë†’ì€ ê°€ì¤‘ì¹˜, í‚¤ì›Œë“œì™€ ì œëª©ì€ ë‚®ì€ ê°€ì¤‘ì¹˜)
            total_similarity = (description_similarity * 0.5) + (keywords_similarity * 0.3) + (title_similarity * 0.2)

            if total_similarity > 0.1:  # ì¼ì • ìˆ˜ì¤€ ì´ìƒì˜ ìœ ì‚¬ë„ë§Œ ì²˜ë¦¬
                job_lat, job_lon = row['latitude'], row['longitude']
                
                # ìœ„ë„/ê²½ë„ê°€ ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
                if pd.isna(job_lat) or pd.isna(job_lon):
                    continue
                
                # ê±°ë¦¬ ê³„ì‚°
                distance = haversine(user_lat, user_lon, job_lat, job_lon)
                if distance is None:
                    distance = float('inf')  # ê±°ë¦¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¬´í•œëŒ€ë¡œ ì²˜ë¦¬
                
                matching_jobs.append({
                    'title': row['title'],
                    'description': row['description'],
                    'address_name': row['address_name'],
                    'latitude': job_lat,
                    'longitude': job_lon,
                    'distance_km': distance,
                    'similarity': total_similarity  # ìœ ì‚¬ë„ ì¶”ê°€
                })

        # ê±°ë¦¬ 30km ì´ìƒì´ë©´ ê±°ë¦¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜, 30km ì´í•˜ë©´ ìœ ì‚¬ë„ ìš°ì„ 
        for job in matching_jobs:
            if job['distance_km'] > 30:
                job['priority_score'] = job['distance_km'] * 0.7 + job['similarity'] * 0.3  # ê±°ë¦¬ ìš°ì„ 
            else:
                job['priority_score'] = job['similarity'] * 0.7 + job['distance_km'] * 0.3  # ìœ ì‚¬ë„ ìš°ì„ 

            # í”¼ë“œë°± ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ìš°ì„ ìˆœìœ„ì— ë°˜ì˜
            job = adjust_priority_with_feedback(job, self.feedback_data)

        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ì— ë”°ë¼ ì •ë ¬
        sorted_jobs = sorted(matching_jobs, key=lambda x: x['priority_score'])
        
        return sorted_jobs

    def generate_response(self, user_input, user_address):
        # ì…ë ¥ëœ ì£¼ì†Œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìœ„ë„, ê²½ë„ ê³„ì‚°
        refined_address = extract_address(user_address)
        full_address, user_lat, user_lon = get_lat_lon_from_address(refined_address, kakao_api_key)
        if user_lat is None or user_lon is None:
            return "ì…ë ¥í•œ ì£¼ì†Œì˜ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì¼ìë¦¬ ì°¾ê¸°
        filtered_jobs = self.find_jobs(user_input, user_lat, user_lon)

        if not filtered_jobs:
            return "ì…ë ¥í•œ í‚¤ì›Œë“œì— ë§ëŠ” ì¼ìë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ ì‘ë‹µ ìƒì„±
        response = f"ì…ë ¥í•œ ì£¼ì†Œ({full_address}) ê¸°ì¤€ìœ¼ë¡œ ê°€ê¹Œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
        for idx, job in enumerate(filtered_jobs[:5]):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            if isinstance(job['distance_km'], (int, float)):
                response += (f"{idx + 1}. **ì œëª©**: {job['title']}\n"
                             f"ğŸ“‹ **ì„¤ëª…**: {job['description']}\n"
                             f"ğŸ  **ì£¼ì†Œ**: {job['address_name']}\n"
                             f"ğŸ“ **ê±°ë¦¬**: {job['distance_km']:.2f}km ë–¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\n"
                             f"âš–ï¸ **ìš°ì„ ìˆœìœ„ ì ìˆ˜**: {job['priority_score']:.2f}\n\n")

        if filtered_jobs:  # ì‘ë‹µì´ ìˆëŠ” ê²½ìš°ì—ë§Œ í”¼ë“œë°± ìš”ì²­
            # ì‚¬ìš©ìê°€ ì‘ë‹µì— ëŒ€í•´ ë§ëŠ”ì§€ í‹€ë¦°ì§€ í”¼ë“œë°±ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ì¶”ê°€
            for idx, job in enumerate(filtered_jobs[:5]):
                feedback = input(f"{idx + 1}. ì´ ì¼ìë¦¬ê°€ ë§ëŠ” ì‘ë‹µì…ë‹ˆê¹Œ? (ë§ìŒ/í‹€ë¦¼): ").strip()
                job_id = job['title']  # íƒ€ì´í‹€ì„ IDë¡œ ì‚¬ìš©
                if feedback == 'ë§ìŒ':
                    self.feedback_data[job_id] = 'ë§ìŒ'
                elif feedback == 'í‹€ë¦¼':
                    self.feedback_data[job_id] = 'í‹€ë¦¼'

            # í”¼ë“œë°± ë°ì´í„°ë¥¼ ì €ì¥
            save_feedback(self.feedback_data)

        return response

if __name__ == "__main__":
    job_data_file = 'job_data.csv'
    chatbot = JobSearchChatbot(job_data_file)

    while True:
        user_input = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        if user_input.lower() == 'exit':
            break
        user_address = input("ì‚¬ìš©ì ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        response = chatbot.generate_response(user_input, user_address)
        print(response)
